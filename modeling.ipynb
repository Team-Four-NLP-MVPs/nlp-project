{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79620f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import acquire\n",
    "import prepare\n",
    "\n",
    "import sklearn as sk\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB, ComplementNB\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34a3b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('data.json')\n",
    "df = prepare.prep_repos(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5f563de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>original</th>\n",
       "      <th>clean</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>language_reduced</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google/googletest</td>\n",
       "      <td>C++</td>\n",
       "      <td># GoogleTest\\n\\n### Announcements\\n\\n#### Live...</td>\n",
       "      <td>googletest announcements live head googletest ...</td>\n",
       "      <td>googletest announc live head googletest follow...</td>\n",
       "      <td>googletest announcement live head googletest f...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>projectdiscovery/nuclei-templates</td>\n",
       "      <td>Python</td>\n",
       "      <td>\\n\\n&lt;h1 align=\"center\"&gt;\\nNuclei Templates\\n&lt;/h...</td>\n",
       "      <td>h1 aligncenter nuclei templates h1 h4 aligncen...</td>\n",
       "      <td>h1 aligncent nuclei templat h1 h4 aligncenterc...</td>\n",
       "      <td>h1 aligncenter nucleus template h1 h4 aligncen...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>digitalocean/nginxconfig.io</td>\n",
       "      <td>JavaScript</td>\n",
       "      <td>[![GitHub stars](https://img.shields.io/github...</td>\n",
       "      <td>github stars https imgshieldsio github stars d...</td>\n",
       "      <td>github star http imgshieldsio github star digi...</td>\n",
       "      <td>github star http imgshieldsio github star digi...</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>flutter/flutter</td>\n",
       "      <td>Dart</td>\n",
       "      <td># [![Flutter logo][]][flutter.dev]\\n\\n[![Build...</td>\n",
       "      <td>flutter logo flutterdev build status cirrus bu...</td>\n",
       "      <td>flutter logo flutterdev build statu cirru buil...</td>\n",
       "      <td>flutter logo flutterdev build status cirrus bu...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PaddlePaddle/PaddleOCR</td>\n",
       "      <td>Python</td>\n",
       "      <td>English | [简体中文](README_ch.md)\\n\\n&lt;p align=\"ce...</td>\n",
       "      <td>english readmechmd p aligncenter img src doc p...</td>\n",
       "      <td>english readmechmd p aligncent img src doc pad...</td>\n",
       "      <td>english readmechmd p aligncenter img src doc p...</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                repo    language  \\\n",
       "0                  google/googletest         C++   \n",
       "1  projectdiscovery/nuclei-templates      Python   \n",
       "2        digitalocean/nginxconfig.io  JavaScript   \n",
       "3                    flutter/flutter        Dart   \n",
       "4             PaddlePaddle/PaddleOCR      Python   \n",
       "\n",
       "                                            original  \\\n",
       "0  # GoogleTest\\n\\n### Announcements\\n\\n#### Live...   \n",
       "1  \\n\\n<h1 align=\"center\">\\nNuclei Templates\\n</h...   \n",
       "2  [![GitHub stars](https://img.shields.io/github...   \n",
       "3  # [![Flutter logo][]][flutter.dev]\\n\\n[![Build...   \n",
       "4  English | [简体中文](README_ch.md)\\n\\n<p align=\"ce...   \n",
       "\n",
       "                                               clean  \\\n",
       "0  googletest announcements live head googletest ...   \n",
       "1  h1 aligncenter nuclei templates h1 h4 aligncen...   \n",
       "2  github stars https imgshieldsio github stars d...   \n",
       "3  flutter logo flutterdev build status cirrus bu...   \n",
       "4  english readmechmd p aligncenter img src doc p...   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  googletest announc live head googletest follow...   \n",
       "1  h1 aligncent nuclei templat h1 h4 aligncenterc...   \n",
       "2  github star http imgshieldsio github star digi...   \n",
       "3  flutter logo flutterdev build statu cirru buil...   \n",
       "4  english readmechmd p aligncent img src doc pad...   \n",
       "\n",
       "                                          lemmatized language_reduced  \n",
       "0  googletest announcement live head googletest f...            Other  \n",
       "1  h1 aligncenter nucleus template h1 h4 aligncen...           Python  \n",
       "2  github star http imgshieldsio github star digi...       JavaScript  \n",
       "3  flutter logo flutterdev build status cirrus bu...            Other  \n",
       "4  english readmechmd p aligncenter img src doc p...           Python  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b535a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'language_reduced'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d928c1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train\t n = 64\n",
      "validate n = 28\n",
      "test\t n = 23\n"
     ]
    }
   ],
   "source": [
    "train, validate, test = prepare.split_data(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f0c7afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_baseline(train, \n",
    "                 model_number, \n",
    "                 model_results):\n",
    "    \n",
    "    # establish baseline predictions for train sample\n",
    "    y_pred = pd.Series([train[target].mode()[0]]).repeat(len(train))\n",
    "    \n",
    "    # get model performance metrics\n",
    "    \n",
    "    # create dictionaries for each metric type for the train sample and \n",
    "    # append those dictionaries to the model_results df\n",
    "    dct = {'model_number': 'baseline',\n",
    "           'model_type': 'baseline',\n",
    "           'sample_type': 'train',\n",
    "           'accuracy': sk.metrics.accuracy_score(train[target], y_pred)}\n",
    "    model_results = model_results.append(dct, ignore_index=True)\n",
    "    \n",
    "    # reset the model_number from 'baseline' to 0\n",
    "    model_number = 0\n",
    "    \n",
    "    return model_number, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64749b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number = 0 \n",
    "model_results = pd.DataFrame()\n",
    "\n",
    "model_number, model_results = run_baseline(train, \n",
    "                                           model_number, \n",
    "                                           model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6efcf501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4efe1273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th>sample_type</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>baseline</td>\n",
       "      <td>train</td>\n",
       "      <td>0.65625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_number model_type sample_type  accuracy\n",
       "0     baseline   baseline       train   0.65625"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5eccd630",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_decision_tree(train, validate, target,\n",
    "                      model_number, model_results):\n",
    "    \n",
    "    # split into x and y\n",
    "    x_train = train.lemmatized\n",
    "    y_train = train[target]\n",
    "    \n",
    "    x_validate = validate.lemmatized\n",
    "    y_validate = validate[target]\n",
    "    \n",
    "    min_max_depth = 3\n",
    "    max_max_depth = 10\n",
    "    \n",
    "    for max_depth in range(min_max_depth, max_max_depth+1):\n",
    "        \n",
    "        \n",
    "        \n",
    "        # create classifier tree object\n",
    "        tree = DecisionTreeClassifier(max_depth=max_depth)\n",
    "       \n",
    "        #################\n",
    "        #### TF-IDF #####\n",
    "        #################\n",
    "        \n",
    "        model_number += 1\n",
    "        model_type = 'decision_tree'\n",
    "        feature_type = 'TF-IDF'\n",
    "        \n",
    "        # create the model\n",
    "        tfidf = TfidfVectorizer().fit(x_train)\n",
    "        x_tfidf = tfidf.transform(x_train)\n",
    "        tree.fit(x_tfidf, y_train)\n",
    "        \n",
    "        # store info about the model\n",
    "        \n",
    "        ####################\n",
    "        ### train sample ###\n",
    "        ####################\n",
    "            \n",
    "        # create a dictionary containing the features and hyperparameters\n",
    "        # used in this model instance\n",
    "        dct = {'model_number': model_number,\n",
    "               'model_type': model_type,\n",
    "               'sample_type': 'train',\n",
    "               'feature_type': feature_type,\n",
    "               'max_depth': max_depth,\n",
    "               'accuracy': tree.score(tfidf.transform(x_train), y_train)}\n",
    "        # append that dictionary to the model_results dataframe\n",
    "        model_results = model_results.append(dct, ignore_index=True)\n",
    "        \n",
    "        #######################\n",
    "        ### validate sample ###\n",
    "        #######################\n",
    "        \n",
    "        # create a dictionary containing the features and hyperparameters\n",
    "        # used in this model instance\n",
    "        dct = {'model_number': model_number,\n",
    "               'model_type': model_type,\n",
    "               'sample_type': 'validate',\n",
    "               'feature_type': feature_type,\n",
    "               'max_depth': max_depth,\n",
    "               'accuracy': tree.score(tfidf.transform(x_validate), y_validate)}\n",
    "        # append that dictionary to the model_results dataframe\n",
    "        model_results = model_results.append(dct, ignore_index=True)\n",
    "        \n",
    "        ##############\n",
    "        ### CV/BOW ###\n",
    "        ##############\n",
    "        \n",
    "        model_number += 1\n",
    "        model_type = 'decision_tree'\n",
    "        feature_type = 'CV/BOW'\n",
    "        \n",
    "        # create the model\n",
    "        cv = CountVectorizer().fit(x_train)\n",
    "        x_cv = cv.transform(x_train)\n",
    "        tree.fit(x_cv, y_train)\n",
    "        \n",
    "        # store info about the model\n",
    "        \n",
    "        ####################\n",
    "        ### train sample ###\n",
    "        ####################\n",
    "            \n",
    "        # create a dictionary containing the features and hyperparameters\n",
    "        # used in this model instance\n",
    "        dct = {'model_number': model_number,\n",
    "               'model_type': model_type,\n",
    "               'sample_type': 'train',\n",
    "               'feature_type': feature_type,\n",
    "               'max_depth': max_depth,\n",
    "               'accuracy': tree.score(cv.transform(x_train), y_train)}\n",
    "        # append that dictionary to the model_results dataframe\n",
    "        model_results = model_results.append(dct, ignore_index=True)\n",
    "        \n",
    "        #######################\n",
    "        ### validate sample ###\n",
    "        #######################\n",
    "        \n",
    "        # create a dictionary containing the features and hyperparameters\n",
    "        # used in this model instance\n",
    "        dct = {'model_number': model_number,\n",
    "               'model_type': model_type,\n",
    "               'sample_type': 'validate',\n",
    "               'feature_type': feature_type,\n",
    "               'max_depth': max_depth,\n",
    "               'accuracy': tree.score(cv.transform(x_validate), y_validate)}\n",
    "        # append that dictionary to the model_results dataframe\n",
    "        model_results = model_results.append(dct, ignore_index=True)\n",
    "        \n",
    "        \n",
    "    return model_number, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05c6dec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number, model_results = run_decision_tree(train, validate, target,\n",
    "                                                model_number, model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78b7476e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_results[model_results.sample_type == 'validate'].accuracy.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c810bcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_random_forest(train, validate, target,\n",
    "                      model_number, model_results):\n",
    "    \n",
    "    # split into x and y\n",
    "    x_train = train.lemmatized\n",
    "    y_train = train[target]\n",
    "    \n",
    "    x_validate = validate.lemmatized\n",
    "    y_validate = validate[target]\n",
    "    \n",
    "    # set hyperparameters\n",
    "    min_max_depth = 3\n",
    "    max_max_depth = 6\n",
    "    min_min_samples_leaf = 3\n",
    "    max_min_samples_leaf = 6\n",
    "    \n",
    "    for max_depth in range(min_max_depth, \n",
    "                           max_max_depth+1):\n",
    "        for min_samples_leaf in range(min_min_samples_leaf, \n",
    "                                      max_min_samples_leaf+1):\n",
    "            \n",
    "            clf = RandomForestClassifier(min_samples_leaf=min_samples_leaf,\n",
    "                                         max_depth=max_depth)\n",
    "            \n",
    "            ############\n",
    "            ## TF-IDF ##\n",
    "            ############\n",
    "            \n",
    "            model_number += 1\n",
    "            model_type = 'random_forest'\n",
    "            feature_type = 'TF-IDF'\n",
    "\n",
    "            \n",
    "            # create the model\n",
    "            tfidf = TfidfVectorizer().fit(x_train)\n",
    "            x_tfidf = tfidf.transform(x_train)\n",
    "            clf.fit(x_tfidf, y_train)\n",
    "            \n",
    "            # store info about the model\n",
    "            \n",
    "            ####################\n",
    "            ### train sample ###\n",
    "            ####################\n",
    "            \n",
    "            # create a dictionary containing the features and hyperparameters\n",
    "            # used in this model instance\n",
    "            dct = {'model_number': model_number,\n",
    "                   'model_type': model_type,\n",
    "                   'sample_type': 'train',\n",
    "                   'feature_type': feature_type,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'accuracy': clf.score(tfidf.transform(x_train), y_train)}\n",
    "            # append that dictionary to the model_results dataframe\n",
    "            model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "            #######################\n",
    "            ### validate sample ###\n",
    "            #######################\n",
    "\n",
    "            # create a dictionary containing the features and hyperparameters\n",
    "            # used in this model instance\n",
    "            dct = {'model_number': model_number,\n",
    "                   'model_type': model_type,\n",
    "                   'sample_type': 'validate',\n",
    "                   'feature_type': feature_type,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'accuracy': clf.score(tfidf.transform(x_validate), y_validate)}\n",
    "            # append that dictionary to the model_results dataframe\n",
    "            model_results = model_results.append(dct, ignore_index=True)\n",
    "            \n",
    "            ##############\n",
    "            ### CV/BOW ###\n",
    "            ##############\n",
    "\n",
    "            model_number += 1\n",
    "            model_type = 'random_forest'\n",
    "            feature_type = 'CV/BOW'\n",
    "\n",
    "            # create the model\n",
    "            cv = CountVectorizer().fit(x_train)\n",
    "            x_cv = cv.transform(x_train)\n",
    "            clf.fit(x_cv, y_train)\n",
    "\n",
    "            # store info about the model\n",
    "\n",
    "            ####################\n",
    "            ### train sample ###\n",
    "            ####################\n",
    "\n",
    "            # create a dictionary containing the features and hyperparameters\n",
    "            # used in this model instance\n",
    "            dct = {'model_number': model_number,\n",
    "                   'model_type': model_type,\n",
    "                   'sample_type': 'train',\n",
    "                   'feature_type': feature_type,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'accuracy': clf.score(cv.transform(x_train), y_train)}\n",
    "            # append that dictionary to the model_results dataframe\n",
    "            model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "            #######################\n",
    "            ### validate sample ###\n",
    "            #######################\n",
    "\n",
    "            # create a dictionary containing the features and hyperparameters\n",
    "            # used in this model instance\n",
    "            dct = {'model_number': model_number,\n",
    "                   'model_type': model_type,\n",
    "                   'sample_type': 'validate',\n",
    "                   'feature_type': feature_type,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_leaf': min_samples_leaf,\n",
    "                   'accuracy': clf.score(cv.transform(x_validate), y_validate)}\n",
    "            # append that dictionary to the model_results dataframe\n",
    "            model_results = model_results.append(dct, ignore_index=True)\n",
    "            \n",
    "    return model_number, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b926e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number, model_results = run_random_forest(train, validate, target,\n",
    "                                               model_number, model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7f825868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_naive_bayes(train, validate, target,\n",
    "                    model_number, model_results):\n",
    "    \n",
    "    # split into x and y\n",
    "    x_train = train.lemmatized\n",
    "    y_train = train[target]\n",
    "    \n",
    "    x_validate = validate.lemmatized\n",
    "    y_validate = validate[target]\n",
    "    \n",
    "    # set hyperparameters\n",
    "    for alpha in [.1, .5, 1, 1.5, 2]:\n",
    "        for classifier, model_type in zip([MultinomialNB(alpha=alpha), ComplementNB(alpha=alpha)], \n",
    "                                          ['MultinomialNB', 'ComplementNB']):\n",
    "\n",
    "            # create the model\n",
    "            clf = classifier\n",
    "\n",
    "            ############\n",
    "            ## TF-IDF ##\n",
    "            ############\n",
    "\n",
    "            model_number += 1\n",
    "            model_type = model_type\n",
    "            feature_type = 'TF-IDF'\n",
    "\n",
    "            # fit the model\n",
    "            tfidf = TfidfVectorizer().fit(x_train)\n",
    "            x_tfidf = tfidf.transform(x_train)\n",
    "            clf.fit(x_tfidf, y_train)\n",
    "\n",
    "            # store info about the model\n",
    "\n",
    "            ####################\n",
    "            ### train sample ###\n",
    "            ####################\n",
    "\n",
    "            # create a dictionary containing the features and hyperparameters\n",
    "            # used in this model instance\n",
    "            dct = {'model_number': model_number,\n",
    "                   'model_type': model_type,\n",
    "                   'sample_type': 'train',\n",
    "                   'feature_type': feature_type,\n",
    "                   'alpha': alpha,\n",
    "                   'accuracy': clf.score(tfidf.transform(x_train), y_train)}\n",
    "            # append that dictionary to the model_results dataframe\n",
    "            model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "            #######################\n",
    "            ### validate sample ###\n",
    "            #######################\n",
    "\n",
    "            # create a dictionary containing the features and hyperparameters\n",
    "            # used in this model instance\n",
    "            dct = {'model_number': model_number,\n",
    "                   'model_type': model_type,\n",
    "                   'sample_type': 'validate',\n",
    "                   'feature_type': feature_type,\n",
    "                   'alpha': alpha,\n",
    "                   'accuracy': clf.score(tfidf.transform(x_validate), y_validate)}\n",
    "            # append that dictionary to the model_results dataframe\n",
    "            model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "            ##############\n",
    "            ### CV/BOW ###\n",
    "            ##############\n",
    "\n",
    "            model_number += 1\n",
    "            model_type = model_type\n",
    "            feature_type = 'CV/BOW'\n",
    "\n",
    "            # create the model\n",
    "            cv = CountVectorizer().fit(x_train)\n",
    "            x_cv = cv.transform(x_train)\n",
    "            clf.fit(x_cv, y_train)\n",
    "\n",
    "            # store info about the model\n",
    "\n",
    "            ####################\n",
    "            ### train sample ###\n",
    "            ####################\n",
    "\n",
    "            # create a dictionary containing the features and hyperparameters\n",
    "            # used in this model instance\n",
    "            dct = {'model_number': model_number,\n",
    "                   'model_type': model_type,\n",
    "                   'sample_type': 'train',\n",
    "                   'feature_type': feature_type,\n",
    "                   'alpha': alpha,\n",
    "                   'accuracy': clf.score(cv.transform(x_train), y_train)}\n",
    "            # append that dictionary to the model_results dataframe\n",
    "            model_results = model_results.append(dct, ignore_index=True)\n",
    "\n",
    "            #######################\n",
    "            ### validate sample ###\n",
    "            #######################\n",
    "\n",
    "            # create a dictionary containing the features and hyperparameters\n",
    "            # used in this model instance\n",
    "            dct = {'model_number': model_number,\n",
    "                   'model_type': model_type,\n",
    "                   'sample_type': 'validate',\n",
    "                   'feature_type': feature_type,\n",
    "                   'alpha': alpha,\n",
    "                   'accuracy': clf.score(cv.transform(x_validate), y_validate)}\n",
    "            # append that dictionary to the model_results dataframe\n",
    "            model_results = model_results.append(dct, ignore_index=True)\n",
    "            \n",
    "    return model_number, model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6432debb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number, model_results = run_naive_bayes(train, validate, target,\n",
    "                                                model_number, model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e70608b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(model_results):\n",
    "    '''\n",
    "    This function takes in the model_results dataframe. This is a dataframe in tidy data format \n",
    "    containing the following information for each model created in the project:\n",
    "    - model number\n",
    "    - sample type\n",
    "    - feature_type\n",
    "    - hypterparameter values\n",
    "    - accuracy (the accuracy score for the given model and sample type)\n",
    "    The function returns a pivot table of those values for easy comparison of models, metrics, and samples. \n",
    "    '''\n",
    "    # create a pivot table of the model_results dataframe\n",
    "    # establish columns as the model_number, with index grouped by metric_type then sample_type, and values as score\n",
    "    # the aggfunc uses a lambda to return each individual score without any aggregation applied\n",
    "    return model_results.pivot_table(columns=['model_number', 'model_type'], \n",
    "                                     index=('sample_type'), \n",
    "                                     values='accuracy',\n",
    "                                     aggfunc=lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "21776e83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_type</th>\n",
       "      <th>train</th>\n",
       "      <th>validate</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_number</th>\n",
       "      <th>model_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.464286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <th>decision_tree</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.703125</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <th>random_forest</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <th>MultinomailNB</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <th>MultinomailNB</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <th>MultinomailNB</th>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <th>MultinomailNB</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <th>MultinomailNB</th>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.890625</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.953125</td>\n",
       "      <td>0.535714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <th>MultinomialNB</th>\n",
       "      <td>0.828125</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.859375</td>\n",
       "      <td>0.642857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <th>ComplementNB</th>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.607143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <th>baseline</th>\n",
       "      <td>0.656250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "sample_type                    train  validate\n",
       "model_number model_type                       \n",
       "1            decision_tree  0.812500  0.357143\n",
       "2            decision_tree  0.765625  0.607143\n",
       "3            decision_tree  0.890625  0.464286\n",
       "4            decision_tree  0.875000  0.428571\n",
       "5            decision_tree  0.937500  0.571429\n",
       "6            decision_tree  0.906250  0.714286\n",
       "7            decision_tree  0.968750  0.535714\n",
       "8            decision_tree  0.937500  0.642857\n",
       "9            decision_tree  0.984375  0.535714\n",
       "10           decision_tree  0.984375  0.535714\n",
       "11           decision_tree  0.984375  0.535714\n",
       "12           decision_tree  0.984375  0.607143\n",
       "13           decision_tree  0.984375  0.535714\n",
       "14           decision_tree  0.984375  0.571429\n",
       "15           decision_tree  0.984375  0.535714\n",
       "16           decision_tree  0.984375  0.607143\n",
       "17           random_forest  0.703125  0.642857\n",
       "18           random_forest  0.671875  0.642857\n",
       "19           random_forest  0.656250  0.642857\n",
       "20           random_forest  0.656250  0.642857\n",
       "21           random_forest  0.656250  0.642857\n",
       "22           random_forest  0.656250  0.642857\n",
       "23           random_forest  0.656250  0.642857\n",
       "24           random_forest  0.656250  0.642857\n",
       "25           random_forest  0.718750  0.642857\n",
       "26           random_forest  0.718750  0.642857\n",
       "27           random_forest  0.656250  0.642857\n",
       "28           random_forest  0.656250  0.642857\n",
       "29           random_forest  0.656250  0.642857\n",
       "30           random_forest  0.656250  0.642857\n",
       "31           random_forest  0.656250  0.642857\n",
       "32           random_forest  0.656250  0.642857\n",
       "33           random_forest  0.734375  0.642857\n",
       "34           random_forest  0.687500  0.642857\n",
       "35           random_forest  0.656250  0.642857\n",
       "36           random_forest  0.656250  0.642857\n",
       "37           random_forest  0.656250  0.642857\n",
       "38           random_forest  0.656250  0.642857\n",
       "39           random_forest  0.656250  0.642857\n",
       "40           random_forest  0.656250  0.642857\n",
       "41           random_forest  0.687500  0.642857\n",
       "42           random_forest  0.687500  0.642857\n",
       "43           random_forest  0.656250  0.642857\n",
       "44           random_forest  0.656250  0.642857\n",
       "45           random_forest  0.656250  0.642857\n",
       "46           random_forest  0.656250  0.642857\n",
       "47           random_forest  0.656250  0.642857\n",
       "48           random_forest  0.656250  0.642857\n",
       "49           MultinomialNB  0.890625  0.642857\n",
       "50           MultinomailNB  0.968750  0.571429\n",
       "51           MultinomialNB  0.656250  0.642857\n",
       "52           MultinomailNB  0.953125  0.607143\n",
       "53           MultinomialNB  0.656250  0.642857\n",
       "54           MultinomailNB  0.906250  0.607143\n",
       "55           MultinomialNB  0.656250  0.642857\n",
       "56           MultinomailNB  0.875000  0.607143\n",
       "57           MultinomialNB  0.656250  0.642857\n",
       "58           MultinomailNB  0.828125  0.607143\n",
       "59           MultinomialNB  0.890625  0.642857\n",
       "60           MultinomialNB  0.968750  0.571429\n",
       "61           ComplementNB   0.984375  0.607143\n",
       "62           ComplementNB   0.984375  0.571429\n",
       "63           MultinomialNB  0.656250  0.642857\n",
       "64           MultinomialNB  0.953125  0.607143\n",
       "65           ComplementNB   0.968750  0.607143\n",
       "66           ComplementNB   0.968750  0.535714\n",
       "67           MultinomialNB  0.656250  0.642857\n",
       "68           MultinomialNB  0.906250  0.607143\n",
       "69           ComplementNB   0.937500  0.642857\n",
       "70           ComplementNB   0.953125  0.535714\n",
       "71           MultinomialNB  0.656250  0.642857\n",
       "72           MultinomialNB  0.875000  0.607143\n",
       "73           ComplementNB   0.875000  0.642857\n",
       "74           ComplementNB   0.906250  0.571429\n",
       "75           MultinomialNB  0.656250  0.642857\n",
       "76           MultinomialNB  0.828125  0.607143\n",
       "77           ComplementNB   0.859375  0.642857\n",
       "78           ComplementNB   0.906250  0.607143\n",
       "baseline     baseline       0.656250       NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display_model_results(model_results).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
