{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0c55bf-1e7a-47b7-b2d7-6b15780eb411",
   "metadata": {},
   "source": [
    "## Predicting Programming Languages\n",
    "### Natural Language Processing Among GitHub Repositories\n",
    "By: _AJ Martinez,        \n",
    "Ben Smith,        \n",
    "Nicholas Dougherty_          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c733d06-15ad-40cb-8d58-115a0267c4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading from local CSV...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import unicodedata\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# imports for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud, ImageColorGenerator\n",
    "from PIL import Image\n",
    "\n",
    "# import modules \n",
    "import prepare \n",
    "import acquire \n",
    "#import explore \n",
    "#import model \n",
    "\n",
    "# imports for NLP extraction\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# imports for modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, plot_confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a245d6a2-601f-4b27-8fc9-13ccc33e0669",
   "metadata": {},
   "source": [
    "***\n",
    "## Overview and Goals\n",
    "\n",
    "The goal of this project is to determine the main coding language of a project based on the contents of it's github Readme, using NLP methods. The data was acquired from various repositories on Github. In order to recreate this project you will need to access the json of the data we acquired. During the acquisition of the repo names, we filtered for the word customer, not for any particular reason other than something to filter for.\n",
    "\n",
    "A total of 193 Repos were obtained but after dropping nulls, readmes with Chinese characters, and slimming it down to the top most prevalent languages in our dataset we ended up with data from 106 different documents. The 4 languages that we filtered for were, Java, JavaScript, PHP, and Jupyter Notebook.\n",
    "\n",
    "## Findings\n",
    "\n",
    "We found that a () model using Lemmatized data performed the highest with an accuracy of () on the validate data set. With a final test accuracy of (). This outperformed our baseline accuracy of (). Our model was (list results and whatnot.)\n",
    "\n",
    "### With More Time\n",
    "\n",
    "We'd like to acquire more data to see if we can improve the results for distinguishing among (). Our sample size was fairly small during this project.\n",
    "*** \n",
    "## Acquisition and Preparation\n",
    "\n",
    "Data was obtained through functions that scraped repository collections on GitHub. A list of Universal Resource Locator (URL) endpoints were garnered from the trending portal and then appended to the origin. BeautifulSoup was essential in this regard. Here is a segment of the code used, the full code  can be viewed in the acquire.py script elsewhere in our repository. \n",
    "\n",
    "```\n",
    "# create an empty list to store endpoints\n",
    "    endpoints = []\n",
    "    # go to each url - trending repos daily, weekly, and monthly\n",
    "    for url in ['https://github.com/trending?since=daily&spoken_language_code=en',\n",
    "                'https://github.com/trending?since=weekly&spoken_language_code=en',\n",
    "                'https://github.com/trending?since=monthly&spoken_language_code=en']:\n",
    "        # get the response\n",
    "        response = get(url)\n",
    "        # create the beautiful soup object; It creates a parse tree from page source code\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        # identify html objects containing each repository\n",
    "        for repo in soup.select('.Box-row'):\n",
    "            # pull out the url endpoint for that repo and append to the list\n",
    "            endpoints.append(repo\n",
    "                             .select_one('h1')\n",
    "                             .select_one('a')\n",
    "                             .attrs['href'])\n",
    "```\n",
    "The assimilated data was stored in a .json file, which was then used to obtain our Dataframe, like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803419a4-d9ae-4888-8d5a-c448faa948a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a511b443-26b3-49a2-a3fb-7b14da173cf5",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7213e313-968b-474f-81a7-f34e973d9349",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e450eb3b-f203-49f6-aacd-298c5e44e4c0",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db3b13-c698-4e52-bef1-e05c4832ddb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
